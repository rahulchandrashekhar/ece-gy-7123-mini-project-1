{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yb_dl_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "data_legend = {'loss': [], 'acc': []}\n",
        "\n",
        "\n",
        "def parameter_ctr(model):\n",
        "    total_parameters = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        param = parameter.numel()\n",
        "        total_parameters+=param\n",
        "    print(\"Parameters: \", total_parameters)\n",
        "    return total_parameters\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# ResNET\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, P, N, _C, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        stride = [1, 2, 2, 2]\n",
        "        C = _C\n",
        "        self.in_planes = C\n",
        "        self.N = N\n",
        "        self.P = P\n",
        "        self.conv1 = nn.Conv2d(3, C, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(C)\n",
        "        self.layers1 = nn.ModuleList()\n",
        "\n",
        "        for i in range(0, N):\n",
        "            if i > 0:\n",
        "                C = 2 * C\n",
        "            self.layers1.append(self._make_layer(block, C, num_blocks[i], stride[i]))\n",
        "        self.linear = nn.Linear(C, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        for i in range(0, self.N):\n",
        "            out = self.layers1[i](out)\n",
        "        out = F.avg_pool2d(out, self.P)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def device_info():\n",
        "  if torch.cuda.is_available():\n",
        "    return 'cuda'\n",
        "  else:\n",
        "    return 'cpu'\n",
        "\n",
        "device = device_info()\n",
        "\n",
        "\n",
        "def project1_model(P, N, _C, block, num_blocks):\n",
        "    return ResNet(P, N, _C, block, num_blocks)\n",
        "\n",
        "args = {\"lr\":0.001, \"resume\":False}\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"\\n====== RUNNING ON GPU ======\\n\")\n",
        "else:\n",
        "  print(\"\\n====== RUNNING ON CPU ======\\n\")\n",
        "\n",
        "top_acc = 0\n",
        "start_epoch = 0\n",
        "\n",
        "# Data\n",
        "print('Augmenting Data...')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_test = transforms.ToTensor()\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('\\nBuilding model...')\n",
        "\n",
        "net = project1_model(3, 4, 32, BasicBlock, [4,4,4,3])\n",
        "total_parameters = parameter_ctr(net)\n",
        "\n",
        "if total_parameters < 5000000:\n",
        "    net = net.to(device)\n",
        "    if device == 'cuda':\n",
        "        net = torch.nn.DataParallel(net)\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "\n",
        "# Loading Checkpoint\n",
        "    if args['resume']:\n",
        "        print('Loading from checkpoint...')\n",
        "        assert os.path.isdir('checkpoint'), 'Checkpoint Empty'\n",
        "        checkpoint = torch.load('./checkpoint/checkpoint.pth')\n",
        "        net.load_state_dict(checkpoint['net'])\n",
        "        top_acc = checkpoint['acc']\n",
        "        start_epoch = checkpoint['epoch']\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters())\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, verbose=False)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    def train(epoch):\n",
        "        print('\\nEpoch: ', epoch)\n",
        "        net.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_no, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            if batch_no % 100 == 0:\n",
        "              print('Training batch ',batch_no, ' of ', len(train_loader), ' | LOSS: ', train_loss / (batch_no + 1), ' | ACCURACY: ', 100 * correct / total, '%')\n",
        "\n",
        "    def test(epoch):\n",
        "        global top_acc\n",
        "        net.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_no, (inputs, targets) in enumerate(test_loader):\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "                if batch_no % 20 == 0:\n",
        "                  print('Testing batch ',batch_no, ' of ', len(test_loader), ' | LOSS: ', test_loss / (batch_no + 1), ' | ACCURACY: ', 100 * correct / total, '%')\n",
        "\n",
        "        # Save checkpoint.\n",
        "        curr_acc = (100 * correct / total)\n",
        "        if curr_acc > top_acc:\n",
        "            print('Saving Checkpoint...')\n",
        "            state = {\n",
        "                'net': net.state_dict(),\n",
        "                'acc': curr_acc,\n",
        "                'epoch': epoch,\n",
        "            }\n",
        "            if not os.path.isdir('checkpoint'):\n",
        "                os.mkdir('checkpoint')\n",
        "            torch.save(state, './checkpoint/checkpoint.pth')\n",
        "            top_acc = curr_acc\n",
        "\n",
        "    for epoch in range(start_epoch, start_epoch+50):\n",
        "        train(epoch)\n",
        "        test(epoch)\n",
        "        scheduler.step()\n",
        "\n",
        "print('Highest Accuracy: ', top_acc)"
      ],
      "metadata": {
        "id": "QUXJckbj69Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac962670-8cd8-43c4-f349-a63148abf4a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== RUNNING ON GPU ======\n",
            "\n",
            "Augmenting Data...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Building model...\n",
            "Parameters:  4754218\n",
            "Highest Accuracy:  0\n"
          ]
        }
      ]
    }
  ]
}